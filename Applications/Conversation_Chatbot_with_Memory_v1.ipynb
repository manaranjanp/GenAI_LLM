{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Langchain: Conversation Demo"],"metadata":{"id":"XoJ-RGiUo-uJ"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8RSTxnoIozRN","outputId":"994d24b5-7c80-4d83-ca91-adfba13e2480","executionInfo":{"status":"ok","timestamp":1702870511087,"user_tz":-330,"elapsed":20161,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m809.1/809.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0m"]}],"source":["!pip -q install openai langchain huggingface_hub transformers tiktoken"]},{"cell_type":"code","source":["from getpass import getpass"],"metadata":{"id":"3f0RujEWFZNX","executionInfo":{"status":"ok","timestamp":1702870523717,"user_tz":-330,"elapsed":577,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import os\n","\n","os.environ['OPENAI_API_KEY'] = getpass()\n"],"metadata":{"id":"9iIacDfgpB2M","outputId":"9fa73281-e80e-4a52-98ee-78fa4838f5f2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702870526555,"user_tz":-330,"elapsed":2843,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":["··········\n"]}]},{"cell_type":"markdown","source":["\n","## Basic Conversation with ConversationBufferMemory"],"metadata":{"id":"-KB9qA8bpxgJ"}},{"cell_type":"code","source":["from langchain.chains.conversation.memory import ConversationBufferMemory\n","from langchain import OpenAI\n","from langchain.chains import ConversationChain"],"metadata":{"id":"-lzO5PfUpwfv","executionInfo":{"status":"ok","timestamp":1702870561974,"user_tz":-330,"elapsed":1976,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(model_name='text-davinci-003',\n","             temperature=0,\n","             max_tokens = 256)"],"metadata":{"id":"sTiEn3tKp7mZ","executionInfo":{"status":"ok","timestamp":1702870694115,"user_tz":-330,"elapsed":821,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["memory = ConversationBufferMemory()\n"],"metadata":{"id":"9EBuodi9wHwG","executionInfo":{"status":"ok","timestamp":1702870881990,"user_tz":-330,"elapsed":584,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    memory=memory\n",")"],"metadata":{"id":"eF2pCbWqry4a","executionInfo":{"status":"ok","timestamp":1702870883865,"user_tz":-330,"elapsed":2,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi there! I am Manaranjan Pradhan\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"id":"Lrf1bwKy-Vx9","outputId":"1657044b-08b0-4747-bd16-148497b7a252","executionInfo":{"status":"ok","timestamp":1702870886503,"user_tz":-330,"elapsed":866,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["conversation.predict(input=\"Can you help me with some customer support?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"dB3NvFScsRGQ","outputId":"b906bd23-bca8-441e-ff24-e13a29c83804","executionInfo":{"status":"ok","timestamp":1702870890768,"user_tz":-330,"elapsed":590,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:  Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\n","Human: Can you help me with some customer support?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' Absolutely! What kind of customer support do you need?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["print(conversation.memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8NeyECDc-l65","outputId":"8a1246e4-0659-4e93-b81e-147b596cee39","executionInfo":{"status":"ok","timestamp":1702870938421,"user_tz":-330,"elapsed":574,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: Hi there! I am Manaranjan Pradhan\n","AI:  Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\n","Human: Can you help me with some customer support?\n","AI:  Absolutely! What kind of customer support do you need?\n"]}]},{"cell_type":"markdown","source":["## Basic Conversation with ConversationSummaryMemory"],"metadata":{"id":"tdR-2GM_sfEg"}},{"cell_type":"code","source":["from langchain.chains.conversation.memory import ConversationSummaryMemory\n","from langchain import OpenAI\n","from langchain.chains import ConversationChain"],"metadata":{"id":"LLNWdNCpsul3","executionInfo":{"status":"ok","timestamp":1702870975292,"user_tz":-330,"elapsed":574,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(model_name='text-davinci-003',\n","             temperature=0,\n","             max_tokens = 256)"],"metadata":{"id":"kUbCneqQsumE","executionInfo":{"status":"ok","timestamp":1702870976632,"user_tz":-330,"elapsed":774,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["summary_memory = ConversationSummaryMemory(llm=OpenAI())"],"metadata":{"id":"VTaQpp2TsumE","executionInfo":{"status":"ok","timestamp":1702870977217,"user_tz":-330,"elapsed":3,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    memory=summary_memory\n",")"],"metadata":{"id":"wDXSZK7lsumE","executionInfo":{"status":"ok","timestamp":1702870982581,"user_tz":-330,"elapsed":549,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi there! I am Manaranjan Pradhan\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"381c3651-1492-44bc-accf-21d6aa8d65bb","id":"6QNnwCWCsumF","executionInfo":{"status":"ok","timestamp":1702870988221,"user_tz":-330,"elapsed":2603,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["conversation.predict(input=\"Can you help me with some customer support?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"8df298c8-c4cc-421c-e14a-48dbdc640bb0","id":"YXAhBz1ntIOX","executionInfo":{"status":"ok","timestamp":1702870994643,"user_tz":-330,"elapsed":2425,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","The human introduces himself to the AI. The AI greets him and asks what it can do for him.\n","Human: Can you help me with some customer support?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Absolutely! I'm here to help. What kind of customer support do you need?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["conversation.predict(input=\"I need to cancel some items from the previous order?\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"id":"R8R2nsXocuMS","outputId":"35ec8285-03ad-4605-98c8-4d7c8297953e","executionInfo":{"status":"ok","timestamp":1702871068686,"user_tz":-330,"elapsed":2784,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","The human introduces himself to the AI, which greets him and asks what it can do for him. The human then asks for help with customer support, to which the AI responds positively and inquires what kind of customer support is needed.\n","Human: I need to cancel some items from the previous order?\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' Certainly! I can help you with that. Can you please provide me with the order number so I can locate the order?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":20}]},{"cell_type":"code","source":["print(conversation.memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"900912ab-5bb2-4765-b529-12f06ff0c909","id":"94erF8qRtIOX","executionInfo":{"status":"ok","timestamp":1702871105056,"user_tz":-330,"elapsed":615,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The human introduces himself to the AI, which greets him and asks what it can do for him. The human then asks for help with customer support, to which the AI responds positively and inquires what kind of customer support is needed. The human requests to cancel items from a previous order, and the AI confirms it can assist with that and asks for the order number.\n"]}]},{"cell_type":"markdown","source":["## Basic Conversation with ConversationBufferWindowMemory"],"metadata":{"id":"5ovDKMUttXg5"}},{"cell_type":"code","source":["from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n","from langchain import OpenAI\n","from langchain.chains import ConversationChain"],"metadata":{"id":"pyY4p8S1tXg6","executionInfo":{"status":"ok","timestamp":1702871134075,"user_tz":-330,"elapsed":2,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(model_name='text-davinci-003',\n","             temperature=0,\n","             max_tokens = 256)"],"metadata":{"id":"jnf_9Ni6tXg6","executionInfo":{"status":"ok","timestamp":1702871138511,"user_tz":-330,"elapsed":566,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# We set a low k=2, to only keep the last 2 interactions in memory\n","window_memory = ConversationBufferWindowMemory(k=2)\n"],"metadata":{"id":"aZhRObxXtXg6","executionInfo":{"status":"ok","timestamp":1702871139105,"user_tz":-330,"elapsed":4,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    memory=window_memory\n",")"],"metadata":{"id":"qtv7iCSStXg6","executionInfo":{"status":"ok","timestamp":1702871155471,"user_tz":-330,"elapsed":897,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi there! I am Manaranjan Pradhan\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":263},"outputId":"49b5a2ad-df2a-4641-9787-dc9cbc263f1c","id":"SU9hmumXtXg6","executionInfo":{"status":"ok","timestamp":1702871156827,"user_tz":-330,"elapsed":560,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["conversation.predict(input=\"I am looking for some customer support\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":281},"outputId":"f8e760d5-da5d-4f5b-c7d1-6620bf064514","id":"-ANI031otXg6","executionInfo":{"status":"ok","timestamp":1702871168898,"user_tz":-330,"elapsed":1400,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:  Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\n","Human: I am looking for some customer support\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' Sure thing! I can help you with customer support. What kind of customer support do you need?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["conversation.predict(input=\"My TV is not working.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":316},"outputId":"d6ff0d62-6f86-48ef-d1d0-28925b34d53e","id":"xa_Y1vzotXg6","executionInfo":{"status":"ok","timestamp":1702871173418,"user_tz":-330,"elapsed":1144,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:  Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\n","Human: I am looking for some customer support\n","AI:  Sure thing! I can help you with customer support. What kind of customer support do you need?\n","Human: My TV is not working.\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" I'm sorry to hear that your TV is not working. Can you tell me what kind of TV it is and what kind of issue you are having?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["conversation.predict(input=\"When I turn it on it makes some weird sounds and then goes black\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":333},"id":"7A4QCtdOuC7D","outputId":"b04418f4-2daf-407d-c62d-7cd099c4542b","executionInfo":{"status":"ok","timestamp":1702871176053,"user_tz":-330,"elapsed":549,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","Human: I am looking for some customer support\n","AI:  Sure thing! I can help you with customer support. What kind of customer support do you need?\n","Human: My TV is not working.\n","AI:  I'm sorry to hear that your TV is not working. Can you tell me what kind of TV it is and what kind of issue you are having?\n","Human: When I turn it on it makes some weird sounds and then goes black\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' That sounds like a hardware issue. Have you tried unplugging the TV and plugging it back in? That can sometimes help reset the hardware.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["print(conversation.memory.buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"12b7ef83-cefc-4bdb-8871-3b4ead18ee38","id":"afMEzKtGtXg7","executionInfo":{"status":"ok","timestamp":1702871197593,"user_tz":-330,"elapsed":552,"user":{"displayName":"MANARANJAN PRADHAN","userId":"03885802779803335284"}}},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Human: My TV is not working.\n","AI:  I'm sorry to hear that your TV is not working. Can you tell me what kind of TV it is and what kind of issue you are having?\n","Human: When I turn it on it makes some weird sounds and then goes black\n","AI:  That sounds like a hardware issue. Have you tried unplugging the TV and plugging it back in? That can sometimes help reset the hardware.\n"]}]},{"cell_type":"markdown","source":["## Basic Conversation with ConversationSummaryBufferMemory\n","\n","\"It keeps a buffer of recent interactions in memory, but rather than just completely flushing old interactions it compiles them into a summary and uses both\""],"metadata":{"id":"IG9kPvWHuQ6s"}},{"cell_type":"code","source":["from langchain.chains.conversation.memory import ConversationSummaryBufferMemory\n","from langchain import OpenAI\n","from langchain.chains import ConversationChain"],"metadata":{"id":"alYXXicIuQ6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(model_name='text-davinci-003',\n","             temperature=0,\n","             max_tokens = 512)"],"metadata":{"id":"-NFtobEBuQ6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setting k=2, will only keep the last 2 interactions in memory\n","# max_token_limit=40 - token limits needs transformers installed\n","memory = ConversationSummaryBufferMemory(llm=OpenAI(), max_token_limit=40)"],"metadata":{"id":"zz-5UGw6uQ6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation_with_summary = ConversationChain(\n","    llm=llm,\n","    memory=memory,\n","    verbose=True\n",")"],"metadata":{"id":"Bb2u6SQ6uQ6t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation_with_summary.predict(input=\"Hi there! I am Manaranjan Pradhan\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":270},"outputId":"3fbab09e-1760-4320-858f-286a1c5cc449","id":"dVHk9ONEuQ6t"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","\n","Human: Hi there! I am Manaranjan Pradhan\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":63}]},{"cell_type":"code","source":["conversation_with_summary.predict(input=\"I need help with my broken TV\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"01ad3bb8-d5cc-433c-bf53-8c6457aa0302","id":"MwIWdc57uQ6u"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","System: \n","The human introduces himself as Manaranjan Pradhan.\n","AI:  Hi Manaranjan Pradhan! It's nice to meet you. My name is AI. What can I do for you today?\n","Human: I need help with my broken TV\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Sure, I'd be happy to help. Can you tell me a bit more about the issue? What kind of TV do you have and what is the problem you're experiencing?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":64}]},{"cell_type":"code","source":["conversation_with_summary.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"outputId":"692f5ea5-b2fa-4fbf-89bd-94ccc7fc1df8","id":"sGEjep9zuQ6u"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","System: \n","The human introduces himself as Manaranjan Pradhan and the AI greets him. The human then informs the AI of his need for help with his broken TV.\n","AI:  Sure, I'd be happy to help. Can you tell me a bit more about the issue? What kind of TV do you have and what is the problem you're experiencing?\n","Human: It makes weird sounds when i turn it on and then goes black\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' I see. That sounds like a hardware issue. Is the TV still under warranty? That might be the best way to get it fixed.'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["conversation_with_summary.predict(input=\"It seems to be Hardware\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":323},"outputId":"d51199da-e4ee-4ef6-b7f6-8e9ba72c67c1","id":"vC9pHPgTuQ6u"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n","\n","Current conversation:\n","System: \n","The human introduces himself as Manaranjan Pradhan and the AI greets him. The human then informs the AI of his need for help with his broken TV and the AI offers to help. The human explains that the TV makes weird sounds when he turns it on and then goes black.\n","AI:  I see. That sounds like a hardware issue. Is the TV still under warranty? That might be the best way to get it fixed.\n","Human: It seems to be Hardware\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" It's possible that the hardware is malfunctioning. Have you tried resetting the TV? That might help to identify the issue. If that doesn't work, you may need to take it to a repair shop or contact the manufacturer for assistance.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["print(conversation_with_summary.memory.moving_summary_buffer)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"f163343b-bac7-4723-c19f-29be9eeb3dd8","id":"GfmR1ypNuQ6u"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","The human introduces himself as Manaranjan Pradhan and the AI greets him. The human then informs the AI of his need for help with his broken TV and the AI offers to help. The human explains that the TV makes weird sounds when he turns it on and then goes black. The AI suggests that the issue might be a hardware issue and suggests resetting the TV or taking it to a repair shop or contacting the manufacturer for assistance.\n"]}]},{"cell_type":"markdown","source":["## Basic Conversation with Conversation Knowledge Graph Memory"],"metadata":{"id":"cVFzMuHhvRd8"}},{"cell_type":"code","source":["from langchain.chains.conversation.memory import ConversationKGMemory\n","from langchain import OpenAI\n","from langchain.chains import ConversationChain\n","from langchain.prompts.prompt import PromptTemplate"],"metadata":{"id":"adK3Chv6vReJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["llm = OpenAI(model_name='text-davinci-003',\n","             temperature=0,\n","             max_tokens = 256)"],"metadata":{"id":"MlhVMDbsvReJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["template = \"\"\"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n","If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n","\n","Relevant Information:\n","\n","{history}\n","\n","Conversation:\n","Human: {input}\n","AI:\"\"\"\n","prompt = PromptTemplate(\n","    input_variables=[\"history\", \"input\"], template=template\n",")"],"metadata":{"id":"9H3_AGhNvReJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation_with_kg = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    prompt=prompt,\n","    memory=ConversationKGMemory(llm=llm)\n",")"],"metadata":{"id":"bMRt3eMdvReJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation_with_kg.predict(input=\"Hi there! I am Manaranjan\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"outputId":"0c541818-87eb-4d5f-d553-38227c68f932","id":"X6_ptbbCvReJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n","If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n","\n","Relevant Information:\n","\n","\n","\n","Conversation:\n","Human: Hi there! I am Manaranjan\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi Manaranjan! It's nice to meet you. I'm an AI created to help you with your daily tasks. What can I do for you today?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":75}]},{"cell_type":"code","source":["conversation_with_kg.predict(input=\"My TV is broken and I need some customer assistance\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"outputId":"ec74cccf-a15a-4c2a-bd72-cdbf5e333211","id":"6kZFM_YqvReJ"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n","If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n","\n","Relevant Information:\n","\n","\n","\n","Conversation:\n","Human: My TV is broken and I need some customer assistance\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" I'm sorry to hear that. Do you know what the issue is?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":76}]},{"cell_type":"code","source":["conversation_with_kg.predict(input=\"It makes weird sounds when i turn it on and then goes black\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"outputId":"3315ad17-cab0-4770-87d9-a74b654ab789","id":"1mYBMM3CvReK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n","If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n","\n","Relevant Information:\n","\n","\n","\n","Conversation:\n","Human: It makes weird sounds when i turn it on and then goes black\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' That sounds like a hardware issue. Is the device plugged in and receiving power?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":77}]},{"cell_type":"code","source":["conversation_with_kg.predict(input=\"Yes it is and it is still under warranty. my warranty number is A512423\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":341},"outputId":"f8268ba5-985a-4228-eb34-c2825e4a3e5c","id":"bHaY4eQovReK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context.\n","If the AI does not know the answer to a question, it truthfully says it does not know. The AI ONLY uses information contained in the \"Relevant Information\" section and does not hallucinate.\n","\n","Relevant Information:\n","\n","\n","\n","Conversation:\n","Human: Yes it is and it is still under warranty. my warranty number is A512423\n","AI:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" That's great to hear! I'm glad you have a warranty for your product. Is there anything else I can help you with?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["# NetworkX Entity graph\n","import networkx as nx\n","import matplotlib.pyplot as plt\n","\n","# nx.draw(conversation_with_kg.memory.kg, with_labels=True)\n","# plt.show()\n","\n","print(conversation_with_kg.memory.kg)\n","print(conversation_with_kg.memory.kg.get_triples())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"24c81a2f-817d-4353-ad97-07ac73261ae8","id":"pc8XWyGIvReK"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<langchain.graphs.networkx_graph.NetworkxEntityGraph object at 0x7a7d02e720b0>\n","[('Manaranjan', 'Human', 'is'), ('TV', 'True', 'is broken'), ('TV', 'weird sounds', 'makes'), ('TV', 'black', 'goes'), ('Device', 'A512423', 'has warranty number'), ('Device', 'Yes', 'is under warranty')]\n"]}]},{"cell_type":"markdown","source":["## Entity Memory"],"metadata":{"id":"fjqlw-Q2HDLc"}},{"cell_type":"code","source":["from langchain import OpenAI, ConversationChain\n","from langchain.chains.conversation.memory import ConversationEntityMemory\n","from langchain.chains.conversation.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE\n","from pydantic import BaseModel\n","from typing import List, Dict, Any"],"metadata":{"id":"Ud227jNMHEtO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["## The propmpt\n","ENTITY_MEMORY_CONVERSATION_TEMPLATE.template"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"hWZneigxHwd0","outputId":"f5d26bce-4cb1-4198-b2ef-6ed96b4fd912"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{entities}\\n\\nCurrent conversation:\\n{history}\\nLast line:\\nHuman: {input}\\nYou:'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["llm = OpenAI(model_name='text-davinci-003',\n","             temperature=0,\n","             max_tokens = 256)"],"metadata":{"id":"8bwvmRCtHPmD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","conversation = ConversationChain(\n","    llm=llm,\n","    verbose=True,\n","    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n","    memory=ConversationEntityMemory(llm=llm)\n",")"],"metadata":{"id":"cXd58z9dHVxQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conversation.predict(input=\"Hi I am Manaranjan. My TV is broken but it is under warranty.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"id":"-PhxTkMuHWUN","outputId":"0c6eeb84-c7d2-434c-ce58-1fc413d8e9d2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{'Sam': '', 'TV': ''}\n","\n","Current conversation:\n","\n","Last line:\n","Human: Hi I am Sam. My TV is broken but it is under warranty.\n","You:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" Hi Sam, I'm sorry to hear that your TV is broken. Is there anything I can do to help?\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":65}]},{"cell_type":"code","source":["conversation.predict(input=\"How can I get it fixed. The warranty number is A512453\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"id":"Osa-NHDtJxUW","outputId":"4473e9b6-db23-4a1f-d688-191cf0eac8ce"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{'A512453': ''}\n","\n","Current conversation:\n","Human: Hi I am Sam. My TV is broken but it is under warranty.\n","AI:  Hi Sam, I'm sorry to hear that your TV is broken. Is there anything I can do to help?\n","Last line:\n","Human: How can I get it fixed. The warranty number is A512453\n","You:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["\" It looks like your TV is still under warranty. To get it fixed, you'll need to contact the manufacturer and provide them with the warranty number A512453. They should be able to provide you with instructions on how to proceed.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["conversation.memory.entity_cache"],"metadata":{"id":"yKn0evo4KqnV","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5dd52902-e597-47be-c5c3-652e041cac9b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['A512453']"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["conversation.predict(input=\"Can you send the repair person call Dave to fix it?.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":507},"id":"H0VpELTyJ8Hn","outputId":"b2b57c79-1325-444d-fd4b-3e7315e576b8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","\n","\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n","Prompt after formatting:\n","\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n","\n","You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n","\n","You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n","\n","Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n","\n","Context:\n","{'Dave': ''}\n","\n","Current conversation:\n","Human: Hi I am Sam. My TV is broken but it is under warranty.\n","AI:  Hi Sam, I'm sorry to hear that your TV is broken. Is there anything I can do to help?\n","Human: How can I get it fixed. The warranty number is A512453\n","AI:  It looks like your TV is still under warranty. To get it fixed, you'll need to contact the manufacturer and provide them with the warranty number A512453. They should be able to provide you with instructions on how to proceed.\n","Last line:\n","Human: Can you send the repair person call Dave to fix it?.\n","You:\u001b[0m\n","\n","\u001b[1m> Finished chain.\u001b[0m\n"]},{"output_type":"execute_result","data":{"text/plain":["' Sure, I can send Dave to fix your TV. Can you provide me with his contact information so I can arrange for him to come to your location?'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["conversation.memory.entity_cache"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bUQxtMWVKUCe","outputId":"91365981-ceff-4860-ae0d-c05bc2274951"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Dave']"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["from pprint import pprint\n","pprint(conversation.memory.store)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"duh46CpJKyRz","outputId":"3487d2e3-3133-4d8c-9fc2-f10f64237f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'A512453': \"A512453 is the warranty number for Sam's TV.\",\n"," 'Dave': 'Dave is a repair person.',\n"," 'Sam': 'Sam owns a TV that is currently broken and under warranty.',\n"," 'TV': 'TV is under warranty.'}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wmCSoJb9LnYY"},"execution_count":null,"outputs":[]}]}